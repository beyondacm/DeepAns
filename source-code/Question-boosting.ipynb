{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3YIBGx9hWN76"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1563509901678,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "YWSUJwOgWUr9",
    "outputId": "7b469150-2edf-4ea2-a6c0-452021413847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Eb1hhzqWWdm"
   },
   "outputs": [],
   "source": [
    "corpus_name = \"question-comment\"\n",
    "datafile = \"/home/zhipeng/CB/best-answer-superuser/question2comment/question2comments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FB6-6MUPXALJ"
   },
   "outputs": [],
   "source": [
    "def printLines(file, n=10):\n",
    "    with open(file, 'rb') as datafile:\n",
    "        lines = datafile.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 823,
     "status": "ok",
     "timestamp": 1563509910863,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "QrI4iKBoXGEM",
    "outputId": "037910ee-4d66-421f-fb0a-1d2819eb5ee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"ca n't connect to internet in safe mode\\twhat error do you receive while executing `ping 8.8.8.8` ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\tdo you have access to another computer with a dvd burner ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\tat what point it looped ? maybe while loading a specific driver ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\tcan you disable the ethernet card in the bios to see if it is causing the crash ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\tdoes it work if you try a wired connection ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\twhat 's the make and model of the pc ? can you run memtest86+ from a cd/usb ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\twhat else did you change in `msconfig` ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\twill it activate in safe mode with networking enabled ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\tout of curiosity what exactly is on the other end of the cable ?\\n\"\n",
      "b\"ca n't connect to internet in safe mode\\tare any of the checkboxes checked in msconfig - > boot ?\\n\"\n"
     ]
    }
   ],
   "source": [
    "printLines(datafile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hVtyjTftXIPR"
   },
   "outputs": [],
   "source": [
    "# Default word tokens\n",
    "PAD_token = 0  # Used for padding short sentences\n",
    "SOS_token = 1  # Start-of-sentence token\n",
    "EOS_token = 2  # End-of-sentence token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3  # Count SOS, EOS, PAD\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words {} / {} = {:.4f}'.format(\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKQCPtXvXYPy"
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_SYGIGFXfFW"
   },
   "outputs": [],
   "source": [
    "# Read query/response pairs and return a voc object\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading lines...\")\n",
    "    # Read the file and split into lines\n",
    "    lines = open(datafile, encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
    "def filterPair(p):\n",
    "    # Input sequences need to preserve the last word for EOS token\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "# Filter pairs using filterPair condition\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lDb5QIpVXqf7"
   },
   "outputs": [],
   "source": [
    "# Using the functions defined above, return a populated voc object and pairs list\n",
    "def loadPrepareData(corpus_name, datafile):\n",
    "    print(\"Start preparing training data ...\")\n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "    print(\"Counted words:\", voc.num_words)\n",
    "    return voc, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0Bq6HG0XtM0"
   },
   "outputs": [],
   "source": [
    "def trimRareWords(voc, pairs, MIN_COUNT):\n",
    "    # Trim words used under the MIN_COUNT from the voc\n",
    "    voc.trim(MIN_COUNT)\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    for pair in pairs:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"Trimmed from {} pairs to {}, {:.4f} of total\".format(len(pairs), len(keep_pairs), len(keep_pairs) / len(pairs)))\n",
    "    return keep_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16875,
     "status": "ok",
     "timestamp": 1563509936984,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "-KBoqXe9XyGu",
    "outputId": "5951f350-9b9e-4523-84cd-d05c6e05c14b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data ...\n",
      "Reading lines...\n",
      "Read 385670 sentence pairs\n",
      "Trimmed to 282753 sentence pairs\n",
      "Counting words...\n",
      "Counted words: 16147\n",
      "keep_words 16144 / 16144 = 1.0000\n",
      "Trimmed from 282753 pairs to 282753, 1.0000 of total\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 16  # Maximum sentence length to consider\n",
    "voc, pairs = loadPrepareData(corpus_name, datafile)\n",
    "\n",
    "MIN_COUNT = 1    # Minimum word count threshold for trimming\n",
    "# Trim voc and pairs\n",
    "pairs = trimRareWords(voc, pairs, MIN_COUNT)\n",
    "\n",
    "# reverse pairs\n",
    "# pairs = [list(reversed(p)) for p in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 672,
     "status": "ok",
     "timestamp": 1563509940384,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "PgC_zQYRX6Y9",
    "outputId": "6ee8e5d5-6bcc-45c7-8897-cfff547a014f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ca n t connect to internet in safe mode', 'what error do you receive while executing ping . . . ?']\n"
     ]
    }
   ],
   "source": [
    "for e in pairs:\n",
    "  print(e)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzqB9BMgYLPL"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# Returns padded input sequence tensor and lengths\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# Returns padded target sequence tensor, padding mask, and max target length\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# Returns all items for a given batch of pairs\n",
    "def batch2TrainData(voc, pair_batch):\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1563509952959,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "di320U8UY3jM",
    "outputId": "c5ba760a-683b-45ce-d4a3-8e14052754ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[  187,  5050,  1178,    77,  1095],\n",
      "        [ 1336,   385,   873,   111,   998],\n",
      "        [  132,   598,  2131,    95,  1022],\n",
      "        [   56,  4332,     7,   190,  1796],\n",
      "        [  934,    57,   735, 13261,   323],\n",
      "        [   58,    75,   892,    30,  1914],\n",
      "        [  432,   250,     9,  1502,     2],\n",
      "        [   25,   111,   420,  1331,     0],\n",
      "        [  803,    57,     2,     2,     0],\n",
      "        [  170,    76,     0,     0,     0],\n",
      "        [  364,     2,     0,     0,     0],\n",
      "        [ 1036,     0,     0,     0,     0],\n",
      "        [    2,     0,     0,     0,     0]])\n",
      "lengths: tensor([13, 11,  9,  9,  7])\n",
      "target_variable: tensor([[  63,   45,   14,  189,  189],\n",
      "        [ 109,   15,   15,  147,  998],\n",
      "        [  26, 1441,  115,  148,  122],\n",
      "        [ 163,  131,   22,   21,   62],\n",
      "        [ 126, 1181,   58,  190,   15],\n",
      "        [  58,   21,  236,  102,  110],\n",
      "        [ 707,   14, 3156,  190,   21],\n",
      "        [  57,   15,  705,   21,    2],\n",
      "        [  58,   22,   58,    2,    0],\n",
      "        [ 902,   27, 2131,    0,    0],\n",
      "        [  21, 1442,  691,    0,    0],\n",
      "        [   2, 1443, 2157,    0,    0],\n",
      "        [   0,   21,   21,    0,    0],\n",
      "        [   0,    2,    2,    0,    0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 0],\n",
      "        [0, 1, 1, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 14\n"
     ]
    }
   ],
   "source": [
    "# Example for validation\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QaYAUWpDakKL"
   },
   "source": [
    "# Define Models - Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jSGoJkPKZEc_"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        # Convert word indexes to embeddings\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        # Return output and final hidden state\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTMLF4YbjsBV"
   },
   "outputs": [],
   "source": [
    "# Luong attention layer\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1ggvbJnRkB8F"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # Keep for reference\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "         # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # rnn_output shape(1, batch_size, hidden_size) \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        # rnn_output shape(batch_size, hidden_size)\n",
    "        output = self.out(rnn_output)\n",
    "        # output : shape(batch_size, output_size)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rv3kWq4gu0-s"
   },
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        # Note: we run this one step (word) at a time\n",
    "        # Get embedding of current input word\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        # Forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        # Calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
    "        # Concatenate weighted context vector and GRU output using Luong eq. 5\n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "        # Predict next word using Luong eq. 6\n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        # Return output and final hidden state\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Zm12egvseut"
   },
   "outputs": [],
   "source": [
    "# Define Loss\n",
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1563509966758,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "q8npkFaTskQh",
    "outputId": "26a3fe9a-ba7e-47cd-8b54-782262eeef88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1778, 0.1341, 0.1305, 0.1156, 0.1439, 0.1422, 0.1560],\n",
      "        [0.1526, 0.0998, 0.1065, 0.1324, 0.1555, 0.1828, 0.1704],\n",
      "        [0.1676, 0.0996, 0.2507, 0.1525, 0.1012, 0.1075, 0.1208],\n",
      "        [0.1493, 0.1134, 0.1864, 0.1464, 0.0971, 0.1781, 0.1294],\n",
      "        [0.1317, 0.1033, 0.1191, 0.1263, 0.1900, 0.2193, 0.1101]])\n",
      "tensor([[2],\n",
      "        [1],\n",
      "        [5],\n",
      "        [4],\n",
      "        [0]])\n",
      "tensor([[0.1305],\n",
      "        [0.0998],\n",
      "        [0.1075],\n",
      "        [0.0971],\n",
      "        [0.1317]])\n",
      "torch.Size([5, 1])\n",
      "Cross Entropy:\n",
      "tensor([[2.0367],\n",
      "        [2.3041],\n",
      "        [2.2298],\n",
      "        [2.3322],\n",
      "        [2.0271]])\n",
      "tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0]], dtype=torch.uint8)\n",
      "Loss:\n",
      "tensor([2.0367, 2.2298, 2.3322])\n",
      "torch.Size([3])\n",
      "Sum of mask elements (How many elements we are considering): tensor(3)\n",
      "Mean of the Loss: tensor(2.1996)\n",
      "Mean of the corss-entropy loss(without masking) tensor(2.1860)\n"
     ]
    }
   ],
   "source": [
    "# Visualise what's happening in the loss function\n",
    "# decoder_out shape:(batch_size, vocab_size) target_size = (batch_size, 1)\n",
    "dec_o = torch.rand(5, 7)\n",
    "dec_o = F.softmax(dec_o, dim=1)\n",
    "tar = torch.tensor([2, 1, 5, 4, 0], dtype=torch.long)\n",
    "tar = tar.view(-1, 1)\n",
    "mask = torch.tensor([1, 0, 1, 1, 0], dtype=torch.uint8)\n",
    "print(dec_o)\n",
    "print(tar)\n",
    "# Get softmax scores for the expected correct predictions\n",
    "gath_ten = torch.gather(dec_o, 1, tar)\n",
    "print(gath_ten)\n",
    "print(gath_ten.shape)\n",
    "crossEntropy = -torch.log(gath_ten)\n",
    "print(\"Cross Entropy:\")\n",
    "print(crossEntropy)\n",
    "mask = mask.unsqueeze(1)\n",
    "print(mask)\n",
    "loss = crossEntropy.masked_select(mask)\n",
    "print(\"Loss:\")\n",
    "print(loss)\n",
    "print(loss.shape)\n",
    "print(\"Sum of mask elements (How many elements we are considering):\", mask.sum())\n",
    "print(\"Mean of the Loss:\", loss.mean())\n",
    "print(\"Mean of the corss-entropy loss(without masking)\", crossEntropy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1563509976543,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "gJYy9JGpsmYX",
    "outputId": "0edfc4d3-38a8-4ad1-811a-851d35e13aea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable:\n",
      "tensor([[  676,   824,   746,  6782,  6407],\n",
      "        [    7,   138,    58, 11411,   372],\n",
      "        [11808,   374,   618,   400,    57],\n",
      "        [   27,   824,    53,  1777,   245],\n",
      "        [  484,  1265,    27,  1229,    99],\n",
      "        [   73,   250,   902,  5141,    73],\n",
      "        [   80,    77,  1082,  1496,     2],\n",
      "        [   58,   111,   231,     2,     0],\n",
      "        [   79,   107,   776,     0,     0],\n",
      "        [ 4768,   824,   902,     0,     0],\n",
      "        [  794, 15640,     2,     0,     0],\n",
      "        [    2,     2,     0,     0,     0]]) torch.Size([12, 5])\n",
      "lengths:\n",
      "tensor([12, 12, 11,  8,  7]) torch.Size([5])\n",
      "target_variable:\n",
      "tensor([[  12,   12,   77,   94,  380],\n",
      "        [  56,  457,   15,  893,   94],\n",
      "        [  58,   62,  728,  656,   68],\n",
      "        [  13,   15,  231, 4540,   58],\n",
      "        [1054,  110,  224,   62,  237],\n",
      "        [  21,   21,  218,  480,   56],\n",
      "        [   2,    2,   95,    9,  196],\n",
      "        [   0,    0,   21,   58,  197],\n",
      "        [   0,    0,    2, 1420,   21],\n",
      "        [   0,    0,    0,   21,    2],\n",
      "        [   0,    0,    0,    2,    0]]) torch.Size([11, 5])\n",
      "mask:\n",
      "tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1],\n",
      "        [0, 0, 1, 1, 1],\n",
      "        [0, 0, 0, 1, 1],\n",
      "        [0, 0, 0, 1, 0]], dtype=torch.uint8) torch.Size([11, 5])\n",
      "max_target_len: 11\n"
     ]
    }
   ],
   "source": [
    "# Visualizing what's happening in one iteration, only run this for visualization\n",
    "\n",
    "small_batch_size = 5\n",
    "batches = batch2TrainData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "print(\"input_variable:\")\n",
    "print(input_variable, input_variable.shape)\n",
    "print(\"lengths:\")\n",
    "print(lengths, lengths.shape)\n",
    "print(\"target_variable:\")\n",
    "print(target_variable, target_variable.shape)\n",
    "print(\"mask:\") \n",
    "print(mask, mask.shape)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7995,
     "status": "ok",
     "timestamp": 1563509989716,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "ZXdnW78_s6HX",
    "outputId": "11c980cb-fa7f-434a-ae16-111d8e5df7f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters \n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "\n",
    "# Define the Encoder and Decoder\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = DecoderRNN(embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.0001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.0001)\n",
    "# Zero gradients\n",
    "encoder_optimizer.zero_grad()\n",
    "decoder_optimizer.zero_grad()\n",
    "\n",
    "# Set device options\n",
    "input_variable = input_variable.to(device)\n",
    "lengths = lengths.to(device)\n",
    "target_variable = target_variable.to(device)\n",
    "mask = mask.to(device)\n",
    "\n",
    "loss = 0\n",
    "print_losses = []\n",
    "n_totals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1563509993351,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "x3Z3APc4tFHi",
    "outputId": "0c6e75fd-f395-4c6e-d7df-b1dd43d09838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input varialbe: tensor([[  676,   824,   746,  6782,  6407],\n",
      "        [    7,   138,    58, 11411,   372],\n",
      "        [11808,   374,   618,   400,    57],\n",
      "        [   27,   824,    53,  1777,   245],\n",
      "        [  484,  1265,    27,  1229,    99],\n",
      "        [   73,   250,   902,  5141,    73],\n",
      "        [   80,    77,  1082,  1496,     2],\n",
      "        [   58,   111,   231,     2,     0],\n",
      "        [   79,   107,   776,     0,     0],\n",
      "        [ 4768,   824,   902,     0,     0],\n",
      "        [  794, 15640,     2,     0,     0],\n",
      "        [    2,     2,     0,     0,     0]], device='cuda:0') torch.Size([12, 5])\n",
      "Encoder Outputs Shape: tensor([[[-0.0731,  0.1340,  0.0549,  ..., -0.1466, -0.4015,  0.1331],\n",
      "         [-0.2705, -0.3039,  0.1299,  ..., -0.3505,  0.2420, -0.2821],\n",
      "         [-0.2417, -0.3604, -0.0772,  ..., -0.1259,  0.1903, -0.0656],\n",
      "         [ 0.3065,  0.1362,  0.0280,  ...,  0.0671, -0.1792, -0.1618],\n",
      "         [ 0.0448, -0.0348, -0.3049,  ..., -0.1125,  0.1159,  0.1025]],\n",
      "\n",
      "        [[-0.0839,  0.1512,  0.2208,  ..., -0.1039, -0.3621,  0.1815],\n",
      "         [-0.3386, -0.4125,  0.0012,  ..., -0.3243,  0.3628, -0.2725],\n",
      "         [-0.0809, -0.4086, -0.0606,  ..., -0.0384,  0.1265, -0.1203],\n",
      "         [ 0.3045, -0.0835,  0.1677,  ..., -0.1252,  0.0063, -0.1573],\n",
      "         [-0.1696, -0.0519,  0.1374,  ...,  0.0062, -0.0192, -0.0400]],\n",
      "\n",
      "        [[-0.2614, -0.1060,  0.0769,  ..., -0.0318, -0.4070,  0.1949],\n",
      "         [-0.2855, -0.2604, -0.0954,  ..., -0.4193,  0.2930,  0.0307],\n",
      "         [-0.1684, -0.1559, -0.0427,  ...,  0.1093,  0.1393, -0.2830],\n",
      "         [ 0.1068, -0.0410,  0.2229,  ..., -0.1828,  0.2558, -0.0808],\n",
      "         [-0.0242,  0.2855,  0.1135,  ...,  0.1643, -0.2071, -0.0894]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4043,  0.0523,  0.0847,  ...,  0.1821, -0.0333,  0.0772],\n",
      "         [ 0.1708, -0.5106,  0.1777,  ..., -0.1033,  0.0133, -0.1332],\n",
      "         [-0.4425,  0.3939,  0.0341,  ...,  0.2116,  0.1672, -0.5198],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.3782,  0.1777,  0.1172,  ...,  0.2336,  0.0207, -0.0526],\n",
      "         [ 0.5988, -0.2783, -0.0867,  ..., -0.0094, -0.0044,  0.0442],\n",
      "         [-0.0529,  0.2222,  0.0067,  ...,  0.1896,  0.0975, -0.3398],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.3198,  0.2412,  0.0090,  ...,  0.1586,  0.0443, -0.0925],\n",
      "         [ 0.3367, -0.0832, -0.0157,  ...,  0.1477,  0.1598, -0.1757],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([12, 5, 500])\n",
      "Last Encoder Hidden Shape: torch.Size([4, 5, 500])\n",
      "Initial Decoder Input:\n",
      "tensor([[1, 1, 1, 1, 1]], device='cuda:0') torch.Size([1, 5])\n",
      "Initial Decoder hidden state shape: torch.Size([2, 5, 500])\n"
     ]
    }
   ],
   "source": [
    "# encoder_outputs: (max_length, batch_size, hidden_size)\n",
    "# encoder_hidden: (n_layers x num_directions, batch_size, hidden_size)\n",
    "encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "print(\"Input varialbe:\", input_variable, input_variable.shape)\n",
    "print(\"Encoder Outputs Shape:\", encoder_outputs, encoder_outputs.shape)\n",
    "print(\"Last Encoder Hidden Shape:\", encoder_hidden.shape)\n",
    "\n",
    "decoder_input = torch.LongTensor([[SOS_token for _ in range(small_batch_size)]])\n",
    "decoder_input = decoder_input.to(device)\n",
    "print(\"Initial Decoder Input:\")\n",
    "print(decoder_input, decoder_input.shape)\n",
    "\n",
    "# Set initial decoder hidden state to the encoder's final hidden state\n",
    "decoder_hidden = encoder_hidden[:decoder.n_layers] # encoder_hidden[:2,:,:].shape\n",
    "print(\"Initial Decoder hidden state shape:\", decoder_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1563509998187,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "SHzvMGBOtMLg",
    "outputId": "672784b5-5777-42a6-c2be-13ceac072ff0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now lets whats happening in every timestep of the GRU\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([ 12,  12,  77,  94, 380], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[ 12,  12,  77,  94, 380]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.6538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576]\n",
      "5\n",
      "Returned Loss: 9.653800010681152\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([ 56, 457,  15, 893,  94], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[ 56, 457,  15, 893,  94]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.6660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576, 48.33007335662842]\n",
      "10\n",
      "Returned Loss: 9.659907341003418\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([ 58,  62, 728, 656,  68], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[ 58,  62, 728, 656,  68]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625]\n",
      "15\n",
      "Returned Loss: 9.69443448384603\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([  13,   15,  231, 4540,   58], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[  13,   15,  231, 4540,   58]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949]\n",
      "20\n",
      "Returned Loss: 9.704909324645996\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([1054,  110,  224,   62,  237], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[1054,  110,  224,   62,  237]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.6289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621]\n",
      "25\n",
      "Returned Loss: 9.689702224731445\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([ 21,  21, 218, 480,  56], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[ 21,  21, 218, 480,  56]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621, 48.67310047149658]\n",
      "30\n",
      "Returned Loss: 9.69718853632609\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([  2,   2,  95,   9, 196], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[  2,   2,  95,   9, 196]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 5\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621, 48.67310047149658, 48.79556179046631]\n",
      "35\n",
      "Returned Loss: 9.706034796578544\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([  0,   0,  21,  58, 197], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[  0,   0,  21,  58, 197]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([0, 0, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.6829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 3\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621, 48.67310047149658, 48.79556179046631, 29.048704147338867]\n",
      "38\n",
      "Returned Loss: 9.704208474410208\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([   0,    0,    2, 1420,   21], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[   0,    0,    2, 1420,   21]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([0, 0, 1, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 3\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621, 48.67310047149658, 48.79556179046631, 29.048704147338867, 29.37477207183838]\n",
      "41\n",
      "Returned Loss: 9.710602295107957\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([ 0,  0,  0, 21,  2], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[ 0,  0,  0, 21,  2]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([0, 0, 0, 1, 1], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 2\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621, 48.67310047149658, 48.79556179046631, 29.048704147338867, 29.37477207183838, 19.538681030273438]\n",
      "43\n",
      "Returned Loss: 9.713334305341853\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n",
      "Decoder Output Shape: torch.Size([5, 16147])\n",
      "Decoder Hidden Shape: torch.Size([2, 5, 500])\n",
      "Target variable at the current timestep before reshaping: tensor([0, 0, 0, 2, 0], device='cuda:0') torch.Size([5])\n",
      "Decoder input: tensor([[0, 0, 0, 2, 0]], device='cuda:0') torch.Size([1, 5])\n",
      "The mask at the current timestep: tensor([0, 0, 0, 1, 0], device='cuda:0', dtype=torch.uint8) torch.Size([5])\n",
      "Mask Loss: tensor(9.7678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Total: 1\n",
      "[48.26900005340576, 48.33007335662842, 48.81744384765625, 48.68166923522949, 48.14436912536621, 48.67310047149658, 48.79556179046631, 29.048704147338867, 29.37477207183838, 19.538681030273438, 9.767799377441406]\n",
      "44\n",
      "Returned Loss: 9.714572147889571\n",
      "\n",
      "\n",
      "-------------------------------DONE ONE TIMESTEP-------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Now lets whats happening in every timestep of the GRU\")\n",
    "# Assume we are using Teacher Forcing\n",
    "for t in range(max_target_len):\n",
    "  decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "  print(\"Decoder Output Shape:\", decoder_output.shape)\n",
    "  print(\"Decoder Hidden Shape:\", decoder_hidden.shape)\n",
    "  # Teacher forcing : next input is current target\n",
    "  decoder_input = target_variable[t].view(1, -1)\n",
    "  print(\"Target variable at the current timestep before reshaping:\", target_variable[t], target_variable[t].shape)\n",
    "  print(\"Decoder input:\", decoder_input, decoder_input.shape)\n",
    "  # Calculate and accumulate loss\n",
    "  print(\"The mask at the current timestep:\", mask[t], mask[t].shape)\n",
    "  \n",
    "  mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "  print(\"Mask Loss:\", mask_loss)\n",
    "  print(\"Total:\", nTotal)\n",
    "  loss += mask_loss\n",
    "  print_losses.append(mask_loss.item() * nTotal)\n",
    "  print(print_losses)\n",
    "  \n",
    "  n_totals += nTotal\n",
    "  print(n_totals)\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "  returned_loss = sum(print_losses) / n_totals\n",
    "  print(\"Returned Loss:\", returned_loss)\n",
    "  print(\"\\n\")\n",
    "  print(\"-------------------------------DONE ONE TIMESTEP-------------------------------\")\n",
    "  print(\"\\n\")\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YXFHT8xLuCQl"
   },
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, clip, max_length=MAX_LENGTH):\n",
    "\n",
    "    # Zero gradients\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # Set device options\n",
    "    input_variable = input_variable.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    # Initialize variables\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    # Forward pass through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "\n",
    "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    # Set initial decoder hidden state to the encoder's final hidden state\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    # Determine if we are using teacher forcing this iteration\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Forward batch of sequences through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # Teacher forcing: next input is current target\n",
    "            decoder_input = target_variable[t].view(1, -1)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            # No teacher forcing: next input is decoder's own current output\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            # Calculate and accumulate loss\n",
    "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
    "            loss += mask_loss\n",
    "            print_losses.append(mask_loss.item() * nTotal)\n",
    "            n_totals += nTotal\n",
    "\n",
    "    # Perform backpropatation\n",
    "    loss.backward()\n",
    "\n",
    "    # Clip gradients: gradients are modified in place\n",
    "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    # Adjust model weights\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return sum(print_losses) / n_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2m3dQ1qu_As"
   },
   "outputs": [],
   "source": [
    "def trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size, print_every, save_every, clip, corpus_name, loadFilename):\n",
    "\n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                      for _ in range(n_iteration)]\n",
    "\n",
    "    # Initializations\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        start_iteration = checkpoint['iteration'] + 1\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Training...\")\n",
    "    for iteration in range(start_iteration, n_iteration + 1):\n",
    "        training_batch = training_batches[iteration - 1]\n",
    "        # Extract fields from batch\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        # Run a training iteration with batch\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip)\n",
    "        print_loss += loss\n",
    "\n",
    "        # Print progress\n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss / print_every\n",
    "            print(\"Iteration: {}; Percent complete: {:.1f}%; Average loss: {:.4f}\".format(iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "            print_loss = 0\n",
    "\n",
    "        # Save checkpoint\n",
    "        if (iteration % save_every == 0):\n",
    "            directory = os.path.join(save_dir, model_name, corpus_name, '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size))\n",
    "            if not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "            torch.save({\n",
    "                'iteration': iteration,\n",
    "                'en': encoder.state_dict(),\n",
    "                'de': decoder.state_dict(),\n",
    "                'en_opt': encoder_optimizer.state_dict(),\n",
    "                'de_opt': decoder_optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'voc_dict': voc.__dict__,\n",
    "                'embedding': embedding.state_dict()\n",
    "            }, os.path.join(directory, '{}_{}.tar'.format(iteration, 'checkpoint')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MHs1GsuAvC7o"
   },
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41uV52V8vF1V"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length=MAX_LENGTH):\n",
    "    ### Format input sentence as a batch\n",
    "    # words -> indexes\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence)]\n",
    "    # Create lengths tensor\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    # Transpose dimensions of batch to match models' expectations\n",
    "    input_batch = torch.LongTensor(indexes_batch).transpose(0, 1)\n",
    "    # Use appropriate device\n",
    "    input_batch = input_batch.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    # Decode sentence with searcher\n",
    "    tokens, scores = searcher(input_batch, lengths, max_length)\n",
    "    # indexes -> words\n",
    "    decoded_words = [voc.index2word[token.item()] for token in tokens]\n",
    "    return decoded_words\n",
    "\n",
    "\n",
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1563510147508,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "xIfM0OQnvJOA",
    "outputId": "b7832575-235f-4343-8a0d-3a4103aeda6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building encoder and decoder ...\n",
      "Models built and ready to go!\n"
     ]
    }
   ],
   "source": [
    "# Configure models\n",
    "model_name = 'cb_model'\n",
    "attn_model = 'dot'\n",
    "#attn_model = 'general'\n",
    "#attn_model = 'concat'\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "# Set checkpoint to load from; set to None if starting from scratch\n",
    "loadFilename = None\n",
    "checkpoint_iter = 4000\n",
    "#loadFilename = os.path.join(save_dir, model_name, corpus_name,\n",
    "#                            '{}-{}_{}'.format(encoder_n_layers, decoder_n_layers, hidden_size),\n",
    "#                            '{}_checkpoint.tar'.format(checkpoint_iter))\n",
    "\n",
    "\n",
    "# Load model if a loadFilename is provided\n",
    "if loadFilename:\n",
    "    # If loading on same machine the model was trained on\n",
    "    checkpoint = torch.load(loadFilename)\n",
    "    # If loading a model trained on GPU to CPU\n",
    "    #checkpoint = torch.load(loadFilename, map_location=torch.device('cpu'))\n",
    "    encoder_sd = checkpoint['en']\n",
    "    decoder_sd = checkpoint['de']\n",
    "    encoder_optimizer_sd = checkpoint['en_opt']\n",
    "    decoder_optimizer_sd = checkpoint['de_opt']\n",
    "    embedding_sd = checkpoint['embedding']\n",
    "    voc.__dict__ = checkpoint['voc_dict']\n",
    "\n",
    "\n",
    "print('Building encoder and decoder ...')\n",
    "# Initialize word embeddings\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "if loadFilename:\n",
    "    embedding.load_state_dict(embedding_sd)\n",
    "# Initialize encoder & decoder models\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "if loadFilename:\n",
    "    encoder.load_state_dict(encoder_sd)\n",
    "    decoder.load_state_dict(decoder_sd)\n",
    "# Use appropriate device\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)\n",
    "print('Models built and ready to go!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 622029,
     "status": "ok",
     "timestamp": 1563522316297,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "V31ffxn4vOWI",
    "outputId": "9f7bc2ec-6b7c-4a99-cb0a-e2e34018adb5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building optimizers ...\n",
      "Starting Training!\n",
      "Initializing ...\n",
      "Training...\n",
      "Iteration: 500; Percent complete: 0.5%; Average loss: 4.6066\n",
      "Iteration: 1000; Percent complete: 1.0%; Average loss: 3.7589\n",
      "Iteration: 1500; Percent complete: 1.5%; Average loss: 3.3553\n",
      "Iteration: 2000; Percent complete: 2.0%; Average loss: 3.0302\n",
      "Iteration: 2500; Percent complete: 2.5%; Average loss: 2.7734\n",
      "Iteration: 3000; Percent complete: 3.0%; Average loss: 2.5645\n",
      "Iteration: 3500; Percent complete: 3.5%; Average loss: 2.3948\n",
      "Iteration: 4000; Percent complete: 4.0%; Average loss: 2.2362\n",
      "Iteration: 4500; Percent complete: 4.5%; Average loss: 2.1164\n",
      "Iteration: 5000; Percent complete: 5.0%; Average loss: 2.0051\n",
      "Iteration: 5500; Percent complete: 5.5%; Average loss: 1.9057\n",
      "Iteration: 6000; Percent complete: 6.0%; Average loss: 1.8311\n",
      "Iteration: 6500; Percent complete: 6.5%; Average loss: 1.7508\n",
      "Iteration: 7000; Percent complete: 7.0%; Average loss: 1.6991\n",
      "Iteration: 7500; Percent complete: 7.5%; Average loss: 1.6237\n",
      "Iteration: 8000; Percent complete: 8.0%; Average loss: 1.5912\n",
      "Iteration: 8500; Percent complete: 8.5%; Average loss: 1.5380\n",
      "Iteration: 9000; Percent complete: 9.0%; Average loss: 1.4902\n",
      "Iteration: 9500; Percent complete: 9.5%; Average loss: 1.4513\n",
      "Iteration: 10000; Percent complete: 10.0%; Average loss: 1.4230\n",
      "Iteration: 10500; Percent complete: 10.5%; Average loss: 1.4000\n",
      "Iteration: 11000; Percent complete: 11.0%; Average loss: 1.3539\n",
      "Iteration: 11500; Percent complete: 11.5%; Average loss: 1.3348\n",
      "Iteration: 12000; Percent complete: 12.0%; Average loss: 1.3132\n",
      "Iteration: 12500; Percent complete: 12.5%; Average loss: 1.2935\n",
      "Iteration: 13000; Percent complete: 13.0%; Average loss: 1.2713\n",
      "Iteration: 13500; Percent complete: 13.5%; Average loss: 1.2541\n",
      "Iteration: 14000; Percent complete: 14.0%; Average loss: 1.2299\n",
      "Iteration: 14500; Percent complete: 14.5%; Average loss: 1.2057\n",
      "Iteration: 15000; Percent complete: 15.0%; Average loss: 1.1982\n",
      "Iteration: 15500; Percent complete: 15.5%; Average loss: 1.1744\n",
      "Iteration: 16000; Percent complete: 16.0%; Average loss: 1.1685\n",
      "Iteration: 16500; Percent complete: 16.5%; Average loss: 1.1514\n",
      "Iteration: 17000; Percent complete: 17.0%; Average loss: 1.1321\n",
      "Iteration: 17500; Percent complete: 17.5%; Average loss: 1.1296\n",
      "Iteration: 18000; Percent complete: 18.0%; Average loss: 1.1219\n",
      "Iteration: 18500; Percent complete: 18.5%; Average loss: 1.1159\n",
      "Iteration: 19000; Percent complete: 19.0%; Average loss: 1.0999\n",
      "Iteration: 19500; Percent complete: 19.5%; Average loss: 1.0850\n",
      "Iteration: 20000; Percent complete: 20.0%; Average loss: 1.0754\n",
      "Iteration: 20500; Percent complete: 20.5%; Average loss: 1.0672\n",
      "Iteration: 21000; Percent complete: 21.0%; Average loss: 1.0618\n",
      "Iteration: 21500; Percent complete: 21.5%; Average loss: 1.0487\n",
      "Iteration: 22000; Percent complete: 22.0%; Average loss: 1.0401\n",
      "Iteration: 22500; Percent complete: 22.5%; Average loss: 1.0294\n",
      "Iteration: 23000; Percent complete: 23.0%; Average loss: 1.0246\n",
      "Iteration: 23500; Percent complete: 23.5%; Average loss: 1.0162\n",
      "Iteration: 24000; Percent complete: 24.0%; Average loss: 1.0105\n",
      "Iteration: 24500; Percent complete: 24.5%; Average loss: 1.0088\n",
      "Iteration: 25000; Percent complete: 25.0%; Average loss: 1.0022\n",
      "Iteration: 25500; Percent complete: 25.5%; Average loss: 0.9920\n",
      "Iteration: 26000; Percent complete: 26.0%; Average loss: 0.9767\n",
      "Iteration: 26500; Percent complete: 26.5%; Average loss: 0.9790\n",
      "Iteration: 27000; Percent complete: 27.0%; Average loss: 0.9754\n",
      "Iteration: 27500; Percent complete: 27.5%; Average loss: 0.9600\n",
      "Iteration: 28000; Percent complete: 28.0%; Average loss: 0.9599\n",
      "Iteration: 28500; Percent complete: 28.5%; Average loss: 0.9531\n",
      "Iteration: 29000; Percent complete: 29.0%; Average loss: 0.9436\n",
      "Iteration: 29500; Percent complete: 29.5%; Average loss: 0.9434\n",
      "Iteration: 30000; Percent complete: 30.0%; Average loss: 0.9376\n",
      "Iteration: 30500; Percent complete: 30.5%; Average loss: 0.9387\n",
      "Iteration: 31000; Percent complete: 31.0%; Average loss: 0.9305\n",
      "Iteration: 31500; Percent complete: 31.5%; Average loss: 0.9215\n",
      "Iteration: 32000; Percent complete: 32.0%; Average loss: 0.9161\n",
      "Iteration: 32500; Percent complete: 32.5%; Average loss: 0.9116\n",
      "Iteration: 33000; Percent complete: 33.0%; Average loss: 0.9054\n",
      "Iteration: 33500; Percent complete: 33.5%; Average loss: 0.9038\n",
      "Iteration: 34000; Percent complete: 34.0%; Average loss: 0.9007\n",
      "Iteration: 34500; Percent complete: 34.5%; Average loss: 0.8952\n",
      "Iteration: 35000; Percent complete: 35.0%; Average loss: 0.8863\n",
      "Iteration: 35500; Percent complete: 35.5%; Average loss: 0.8818\n",
      "Iteration: 36000; Percent complete: 36.0%; Average loss: 0.8828\n",
      "Iteration: 36500; Percent complete: 36.5%; Average loss: 0.8842\n",
      "Iteration: 37000; Percent complete: 37.0%; Average loss: 0.8648\n",
      "Iteration: 37500; Percent complete: 37.5%; Average loss: 0.8692\n",
      "Iteration: 38000; Percent complete: 38.0%; Average loss: 0.8630\n",
      "Iteration: 38500; Percent complete: 38.5%; Average loss: 0.8554\n",
      "Iteration: 39000; Percent complete: 39.0%; Average loss: 0.8561\n",
      "Iteration: 39500; Percent complete: 39.5%; Average loss: 0.8542\n",
      "Iteration: 40000; Percent complete: 40.0%; Average loss: 0.8516\n",
      "Iteration: 40500; Percent complete: 40.5%; Average loss: 0.8442\n",
      "Iteration: 41000; Percent complete: 41.0%; Average loss: 0.8431\n",
      "Iteration: 41500; Percent complete: 41.5%; Average loss: 0.8412\n",
      "Iteration: 42000; Percent complete: 42.0%; Average loss: 0.8402\n",
      "Iteration: 42500; Percent complete: 42.5%; Average loss: 0.8306\n",
      "Iteration: 43000; Percent complete: 43.0%; Average loss: 0.8288\n",
      "Iteration: 43500; Percent complete: 43.5%; Average loss: 0.8261\n",
      "Iteration: 44000; Percent complete: 44.0%; Average loss: 0.8197\n",
      "Iteration: 44500; Percent complete: 44.5%; Average loss: 0.8218\n",
      "Iteration: 45000; Percent complete: 45.0%; Average loss: 0.8232\n",
      "Iteration: 45500; Percent complete: 45.5%; Average loss: 0.8207\n",
      "Iteration: 46000; Percent complete: 46.0%; Average loss: 0.8082\n",
      "Iteration: 46500; Percent complete: 46.5%; Average loss: 0.8027\n",
      "Iteration: 47000; Percent complete: 47.0%; Average loss: 0.8038\n",
      "Iteration: 47500; Percent complete: 47.5%; Average loss: 0.7991\n",
      "Iteration: 48000; Percent complete: 48.0%; Average loss: 0.8054\n",
      "Iteration: 48500; Percent complete: 48.5%; Average loss: 0.8007\n",
      "Iteration: 49000; Percent complete: 49.0%; Average loss: 0.7958\n",
      "Iteration: 49500; Percent complete: 49.5%; Average loss: 0.7926\n",
      "Iteration: 50000; Percent complete: 50.0%; Average loss: 0.7898\n",
      "Iteration: 50500; Percent complete: 50.5%; Average loss: 0.7885\n",
      "Iteration: 51000; Percent complete: 51.0%; Average loss: 0.7807\n",
      "Iteration: 51500; Percent complete: 51.5%; Average loss: 0.7801\n",
      "Iteration: 52000; Percent complete: 52.0%; Average loss: 0.7805\n",
      "Iteration: 52500; Percent complete: 52.5%; Average loss: 0.7764\n",
      "Iteration: 53000; Percent complete: 53.0%; Average loss: 0.7761\n",
      "Iteration: 53500; Percent complete: 53.5%; Average loss: 0.7757\n",
      "Iteration: 54000; Percent complete: 54.0%; Average loss: 0.7707\n",
      "Iteration: 54500; Percent complete: 54.5%; Average loss: 0.7690\n",
      "Iteration: 55000; Percent complete: 55.0%; Average loss: 0.7675\n",
      "Iteration: 55500; Percent complete: 55.5%; Average loss: 0.7642\n",
      "Iteration: 56000; Percent complete: 56.0%; Average loss: 0.7575\n",
      "Iteration: 56500; Percent complete: 56.5%; Average loss: 0.7561\n",
      "Iteration: 57000; Percent complete: 57.0%; Average loss: 0.7543\n",
      "Iteration: 57500; Percent complete: 57.5%; Average loss: 0.7536\n",
      "Iteration: 58000; Percent complete: 58.0%; Average loss: 0.7510\n",
      "Iteration: 58500; Percent complete: 58.5%; Average loss: 0.7465\n",
      "Iteration: 59000; Percent complete: 59.0%; Average loss: 0.7518\n",
      "Iteration: 59500; Percent complete: 59.5%; Average loss: 0.7510\n",
      "Iteration: 60000; Percent complete: 60.0%; Average loss: 0.7459\n",
      "Iteration: 60500; Percent complete: 60.5%; Average loss: 0.7427\n",
      "Iteration: 61000; Percent complete: 61.0%; Average loss: 0.7376\n",
      "Iteration: 61500; Percent complete: 61.5%; Average loss: 0.7373\n",
      "Iteration: 62000; Percent complete: 62.0%; Average loss: 0.7293\n",
      "Iteration: 62500; Percent complete: 62.5%; Average loss: 0.7327\n",
      "Iteration: 63000; Percent complete: 63.0%; Average loss: 0.7336\n",
      "Iteration: 63500; Percent complete: 63.5%; Average loss: 0.7320\n",
      "Iteration: 64000; Percent complete: 64.0%; Average loss: 0.7328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 64500; Percent complete: 64.5%; Average loss: 0.7221\n",
      "Iteration: 65000; Percent complete: 65.0%; Average loss: 0.7260\n",
      "Iteration: 65500; Percent complete: 65.5%; Average loss: 0.7246\n",
      "Iteration: 66000; Percent complete: 66.0%; Average loss: 0.7280\n",
      "Iteration: 66500; Percent complete: 66.5%; Average loss: 0.7212\n",
      "Iteration: 67000; Percent complete: 67.0%; Average loss: 0.7271\n",
      "Iteration: 67500; Percent complete: 67.5%; Average loss: 0.7240\n",
      "Iteration: 68000; Percent complete: 68.0%; Average loss: 0.7130\n",
      "Iteration: 68500; Percent complete: 68.5%; Average loss: 0.7175\n",
      "Iteration: 69000; Percent complete: 69.0%; Average loss: 0.7161\n",
      "Iteration: 69500; Percent complete: 69.5%; Average loss: 0.7171\n",
      "Iteration: 70000; Percent complete: 70.0%; Average loss: 0.7172\n",
      "Iteration: 70500; Percent complete: 70.5%; Average loss: 0.7161\n",
      "Iteration: 71000; Percent complete: 71.0%; Average loss: 0.7055\n",
      "Iteration: 71500; Percent complete: 71.5%; Average loss: 0.7097\n",
      "Iteration: 72000; Percent complete: 72.0%; Average loss: 0.7005\n",
      "Iteration: 72500; Percent complete: 72.5%; Average loss: 0.7001\n",
      "Iteration: 73000; Percent complete: 73.0%; Average loss: 0.7072\n",
      "Iteration: 73500; Percent complete: 73.5%; Average loss: 0.6997\n",
      "Iteration: 74000; Percent complete: 74.0%; Average loss: 0.7027\n",
      "Iteration: 74500; Percent complete: 74.5%; Average loss: 0.7024\n",
      "Iteration: 75000; Percent complete: 75.0%; Average loss: 0.6953\n",
      "Iteration: 75500; Percent complete: 75.5%; Average loss: 0.6948\n",
      "Iteration: 76000; Percent complete: 76.0%; Average loss: 0.6968\n",
      "Iteration: 76500; Percent complete: 76.5%; Average loss: 0.6952\n",
      "Iteration: 77000; Percent complete: 77.0%; Average loss: 0.6900\n",
      "Iteration: 77500; Percent complete: 77.5%; Average loss: 0.6962\n",
      "Iteration: 78000; Percent complete: 78.0%; Average loss: 0.6924\n",
      "Iteration: 78500; Percent complete: 78.5%; Average loss: 0.6891\n",
      "Iteration: 79000; Percent complete: 79.0%; Average loss: 0.6881\n",
      "Iteration: 79500; Percent complete: 79.5%; Average loss: 0.6895\n",
      "Iteration: 80000; Percent complete: 80.0%; Average loss: 0.6871\n",
      "Iteration: 80500; Percent complete: 80.5%; Average loss: 0.6804\n",
      "Iteration: 81000; Percent complete: 81.0%; Average loss: 0.6845\n",
      "Iteration: 81500; Percent complete: 81.5%; Average loss: 0.6871\n",
      "Iteration: 82000; Percent complete: 82.0%; Average loss: 0.6837\n",
      "Iteration: 82500; Percent complete: 82.5%; Average loss: 0.6873\n",
      "Iteration: 83000; Percent complete: 83.0%; Average loss: 0.6808\n",
      "Iteration: 83500; Percent complete: 83.5%; Average loss: 0.6774\n",
      "Iteration: 84000; Percent complete: 84.0%; Average loss: 0.6857\n",
      "Iteration: 84500; Percent complete: 84.5%; Average loss: 0.6767\n",
      "Iteration: 85000; Percent complete: 85.0%; Average loss: 0.6783\n",
      "Iteration: 85500; Percent complete: 85.5%; Average loss: 0.6737\n",
      "Iteration: 86000; Percent complete: 86.0%; Average loss: 0.6742\n",
      "Iteration: 86500; Percent complete: 86.5%; Average loss: 0.6726\n",
      "Iteration: 87000; Percent complete: 87.0%; Average loss: 0.6745\n",
      "Iteration: 87500; Percent complete: 87.5%; Average loss: 0.6723\n",
      "Iteration: 88000; Percent complete: 88.0%; Average loss: 0.6743\n",
      "Iteration: 88500; Percent complete: 88.5%; Average loss: 0.6742\n",
      "Iteration: 89000; Percent complete: 89.0%; Average loss: 0.6663\n",
      "Iteration: 89500; Percent complete: 89.5%; Average loss: 0.6752\n",
      "Iteration: 90000; Percent complete: 90.0%; Average loss: 0.6701\n",
      "Iteration: 90500; Percent complete: 90.5%; Average loss: 0.6729\n",
      "Iteration: 91000; Percent complete: 91.0%; Average loss: 0.6696\n",
      "Iteration: 91500; Percent complete: 91.5%; Average loss: 0.6633\n",
      "Iteration: 92000; Percent complete: 92.0%; Average loss: 0.6645\n",
      "Iteration: 92500; Percent complete: 92.5%; Average loss: 0.6634\n",
      "Iteration: 93000; Percent complete: 93.0%; Average loss: 0.6599\n",
      "Iteration: 93500; Percent complete: 93.5%; Average loss: 0.6645\n",
      "Iteration: 94000; Percent complete: 94.0%; Average loss: 0.6666\n",
      "Iteration: 94500; Percent complete: 94.5%; Average loss: 0.6679\n",
      "Iteration: 95000; Percent complete: 95.0%; Average loss: 0.6609\n",
      "Iteration: 95500; Percent complete: 95.5%; Average loss: 0.6622\n",
      "Iteration: 96000; Percent complete: 96.0%; Average loss: 0.6592\n",
      "Iteration: 96500; Percent complete: 96.5%; Average loss: 0.6590\n",
      "Iteration: 97000; Percent complete: 97.0%; Average loss: 0.6600\n",
      "Iteration: 97500; Percent complete: 97.5%; Average loss: 0.6601\n",
      "Iteration: 98000; Percent complete: 98.0%; Average loss: 0.6580\n",
      "Iteration: 98500; Percent complete: 98.5%; Average loss: 0.6537\n",
      "Iteration: 99000; Percent complete: 99.0%; Average loss: 0.6567\n",
      "Iteration: 99500; Percent complete: 99.5%; Average loss: 0.6590\n"
     ]
    }
   ],
   "source": [
    "# save_dir = \"./gdrive/My Drive/best-answer/Query-boosting/question-boosting/\"\n",
    "save_dir = \"/home/zhipeng/CB/best-answer-superuser/question2comment/\"\n",
    "\n",
    "# Configure training/optimization\n",
    "clip = 50.0\n",
    "teacher_forcing_ratio = 1.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0\n",
    "n_iteration = 100000\n",
    "print_every = 500\n",
    "save_every = 10000\n",
    "\n",
    "# Ensure dropout layers are in train mode\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "# Initialize optimizers\n",
    "print('Building optimizers ...')\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "if loadFilename:\n",
    "    encoder_optimizer.load_state_dict(encoder_optimizer_sd)\n",
    "    decoder_optimizer.load_state_dict(decoder_optimizer_sd)\n",
    "\n",
    "# Run training iterations\n",
    "print(\"Starting Training!\")\n",
    "trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "           embedding, encoder_n_layers, decoder_n_layers, save_dir, n_iteration, batch_size,\n",
    "           print_every, save_every, clip, corpus_name, loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NziTwH4RvTvd"
   },
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        # Forward input through encoder model\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        # Prepare encoder's final hidden layer to be first hidden input to the decoder\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        # Initialize decoder input with SOS_token\n",
    "        decoder_input = torch.ones(1, 1, device=device, dtype=torch.long) * SOS_token\n",
    "        # Initialize tensors to append decoded words to\n",
    "        all_tokens = torch.zeros([0], device=device, dtype=torch.long)\n",
    "        all_scores = torch.zeros([0], device=device)\n",
    "        # Iteratively decode one word token at a time\n",
    "        for _ in range(max_length):\n",
    "            # Forward pass through decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Obtain most likely word token and its softmax score\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim=1)\n",
    "            # Record token and score\n",
    "            all_tokens = torch.cat((all_tokens, decoder_input), dim=0)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim=0)\n",
    "            # Prepare current token to be next decoder input (add a dimension)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        # Return collections of word tokens and scores\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTPm9cVcx1Vk"
   },
   "outputs": [],
   "source": [
    "def evaluateInput(encoder, decoder, searcher, voc):\n",
    "    # input_sentence = ''\n",
    "    while(1):\n",
    "        try:\n",
    "            # Get input sentence\n",
    "            # input_sentence = input('> ')\n",
    "            # Check if it is quit case\n",
    "            # if input_sentence == 'q' or input_sentence == 'quit': break\n",
    "            pair = random.choice(pairs)\n",
    "            input_sentence, target_sentence = pair[0], pair[1]\n",
    "            # Normalize sentence\n",
    "            input_sentence = normalizeString(input_sentence)\n",
    "            # Evaluate sentence\n",
    "            output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "            # Format and print response sentence\n",
    "            output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "            print('Bot:', ' '.join(output_words))\n",
    "            break\n",
    "            \n",
    "        except KeyError:\n",
    "            print(\"Error: Encountered unknown word.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdqRFiZox3xy"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "  for i in range(n):\n",
    "    pair = random.choice(pairs)\n",
    "    input_sentence, target_sentence = pair[0], pair[1]\n",
    "    print(\">\", pair[0])\n",
    "    print(\"=\", pair[1])\n",
    "    # Normalize sentence\n",
    "    input_sentence = normalizeString(input_sentence)\n",
    "    # print(input_sentence)\n",
    "    # Evaluate sentence\n",
    "    output_words = evaluate(encoder, decoder, searcher, voc, input_sentence)\n",
    "    # Format and print response sentence\n",
    "    output_words[:] = [x for x in output_words if not (x == 'EOS' or x == 'PAD')]\n",
    "    print('Bot:', ' '.join(output_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1094,
     "status": "ok",
     "timestamp": 1563522373144,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "BnX_43umx6KR",
    "outputId": "4eb15598-c313-475d-b5bd-149ec390a8f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> is there a command to get the location of a file which is selected in nautilus ?\n",
      "= do you want a new tab or a new window ?\n",
      "Bot: op are you still looking for an answer ? xterm ? ? ? ? ? ? ? ? ? ? ?\n",
      "> how do i downgrade google chrome ?\n",
      "= what version of ubuntu are you on ?\n",
      "Bot: switching to vmlinuz .old and initrd .img .old did not help why would it have ? ? ? ? ? ? ? ? ?\n",
      "> how to let ubuntu promt my password on the greeter screen instead of the keyring promt ?\n",
      "= so you want to disable the dialogue that asks you to input your password to change system critical settings ?\n",
      "Bot: what desktop environment are you using ? ? maybe ? ? kde ? ? ? ? ? ? ? ? ?\n",
      "> lubuntu . lts installation shows block message\n",
      "= did you use the webcam just before changing ? and was it a clear picture ?\n",
      "Bot: what is cpu model ? of home ? cpu ram ? torrent ? ? ? ? ? ? ? ? ?\n",
      "> gnome . choppy animations with intel hd graphics\n",
      "= are any drivers listed in additional drivers ?\n",
      "Bot: are you running bit ? ? and restoring the cable s ? ? .com ? ? .com ? ? .com ? ?\n",
      "> i took off windows finished the installation and now it keeps asking if i want to install or try it out . what do i do ?\n",
      "= try disabling fast startup in windows does that fix the problem ?\n",
      "Bot: did you remove the installation media ? bar packaging a file ? time list ? ? ? ? ? ? ? ?\n",
      "> can a backup created on a bit installation be restored onto a bit system after upgrade ?\n",
      "= perhaps you had some half installed packages ?\n",
      "Bot: by ntfs file system install do you mean wubi install ? wine ? torrent ? ? ? ? ? ? ? ?\n",
      "> enable opengl in vlc\n",
      "= just in case did you re install the guest additions after the release upgrade ?\n",
      "Bot: what graphics card do you have ? or optimus ? time ? ? ? ? ? ? ? ? ? ?\n",
      "> configure network interface for direct connection\n",
      "= should n t autu eth and autu eth be auto ? is that a typo ?\n",
      "Bot: what is the ip address of the virtual machine ? entry ? ? ? .com ? yes ? .com ? ? ? ?\n",
      "> how do i make taskbar icons appear in gnome ?\n",
      "= could you add a screenshot then ?\n",
      "Bot: which task bar ? ? compiz ? kde ? ? ? ? ? ? ? ? ? ? ? ?\n"
     ]
    }
   ],
   "source": [
    "# Set dropout layers to eval mode\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# Initialize search module\n",
    "searcher = GreedySearchDecoder(encoder, decoder)\n",
    "\n",
    "# Randomly evaluate\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rY6R6V4Zx8UX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "question-boosting.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
