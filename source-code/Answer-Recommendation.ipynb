{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2045,
     "status": "ok",
     "timestamp": 1563357479003,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "R8Pq1Wk1HTOJ",
    "outputId": "057cabe3-8295-4df8-cbd8-2b9a77be6262"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/zhipeng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import shuffle\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLQMm3YxHeOs"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbM9BIVoHeRa"
   },
   "outputs": [],
   "source": [
    "def text_prepare(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = GOOD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11769,
     "status": "ok",
     "timestamp": 1563357492256,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "NYx8Qk57HeUG",
    "outputId": "0ce6ca0f-e174-4bf6-c5c0-d9409f53fa2c"
   },
   "outputs": [],
   "source": [
    "starspace_embeddings = {}\n",
    "for line in open('./starspace_embeddings/mdl.tsv'):\n",
    "    try:\n",
    "      word, *vec = line.strip().split()\n",
    "      vf = []\n",
    "      for v in vec:\n",
    "          vf.append(float(v))\n",
    "      starspace_embeddings[word] = np.array(vf)\n",
    "    except:\n",
    "      # print(word)\n",
    "      # print(*vec)\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1563357496238,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "oA0xyFC8c8M1",
    "outputId": "385f6f9e-ad87-401b-dcd0-432caf082e55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 295698\n"
     ]
    }
   ],
   "source": [
    "print(type(starspace_embeddings), len(starspace_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onEjaBBQHeW7"
   },
   "outputs": [],
   "source": [
    "def query_to_vec(query, embeddings, dim=100):\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  vec = np.zeros((dim,), dtype=np.float32)\n",
    "  count = 0\n",
    "  for w in query.split():\n",
    "    if w in embeddings:\n",
    "      count += 1\n",
    "      vec += embeddings[w]\n",
    "  if count == 0:\n",
    "    return vec\n",
    "  return vec/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k5-Zr31sHeZg"
   },
   "outputs": [],
   "source": [
    "def read_data(data_file):\n",
    "  \n",
    "  X = []\n",
    "  Y = []\n",
    "  \n",
    "  with open(data_file, 'r') as data_file:\n",
    "    for line in data_file:\n",
    "      pid, question, prediction, answer, label = line.split('\\t')\n",
    "\n",
    "      question = text_prepare(question)\n",
    "      answer = text_prepare(answer)\n",
    "      \n",
    "      prediction = text_prepare(prediction)\n",
    "      prediction = [w for w in prediction.split() if w in starspace_embeddings]\n",
    "      prediction = ' '.join(prediction)\n",
    "        \n",
    "      if len(question.split()) > 16 or len(question.split()) < 3:\n",
    "        continue\n",
    "      if len(answer.split()) > 128 or len(answer.split()) < 5:\n",
    "        continue\n",
    "      \n",
    "      # question = [w for w in question.split() if w in starspace_embeddings]\n",
    "      # answer = [w for w in answer.split() if w in starspace_embeddings]\n",
    "      \n",
    "      # question = \" \".join(question)\n",
    "      # answer = \" \".join(answer)\n",
    "      \n",
    "      question = question + \" \" + prediction\n",
    "      qa_pair = (question, answer)\n",
    "      label = int(label)\n",
    "      X.append(qa_pair)\n",
    "      Y.append(label + 2)\n",
    "  \n",
    "  X, Y = shuffle(X, Y, random_state=0)\n",
    "  X = np.asarray(X)\n",
    "  Y = np.asarray(Y)\n",
    "  \n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11305,
     "status": "ok",
     "timestamp": 1563357513899,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "EldClg2tHecU",
    "outputId": "c388f9ab-d436-47ed-e8fb-86c219fbb394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (350522, 2)\n",
      "<class 'numpy.ndarray'> (350522,)\n",
      "\n",
      "<class 'numpy.ndarray'> (42443, 2)\n",
      "<class 'numpy.ndarray'> (42443,)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = read_data('./question2comment/train_expansion_4cls')\n",
    "X_val, Y_val = read_data('./question2comment/validate_expansion_4cls')\n",
    "print(type(X_train), X_train.shape )\n",
    "print(type(Y_train), Y_train.shape )\n",
    "print()\n",
    "print(type(X_val), X_val.shape )\n",
    "print(type(Y_val), Y_val.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "print(set(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6520,
     "status": "ok",
     "timestamp": 1563357513901,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "OGsV0peBHefJ",
    "outputId": "aefebc66-be68-4e0a-ad4b-b633ecd3e164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 <class 'int'>\n",
      "128 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "question_maxlen = max( [len(qapair[0].split()) for qapair in X_val] )\n",
    "print(question_maxlen, type(question_maxlen))\n",
    "answer_maxlen = max( [len(qapair[1].split()) for qapair in X_val] )\n",
    "print(answer_maxlen, type(answer_maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjMgnB-OHeka"
   },
   "outputs": [],
   "source": [
    "Xqtrain = X_train[:, 0]\n",
    "Xatrain = X_train[:, 1]\n",
    "\n",
    "Xqval = X_val[:, 0]\n",
    "Xaval = X_val[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2198,
     "status": "ok",
     "timestamp": 1563357513905,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "aA-vU9PFHenN",
    "outputId": "0811ce80-a653-4fbc-be48-91fc9a02b664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "<class 'numpy.ndarray'> (350522,)\n",
      "<class 'numpy.ndarray'> (350522,)\n",
      "<class 'numpy.ndarray'> (350522,)\n",
      "Validation Set:\n",
      "<class 'numpy.ndarray'> (42443,)\n",
      "<class 'numpy.ndarray'> (42443,)\n",
      "<class 'numpy.ndarray'> (42443,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set:\")\n",
    "print(type(Xqtrain), Xqtrain.shape)\n",
    "print(type(Xatrain), Xatrain.shape)\n",
    "print(type(Y_train), Y_train.shape)\n",
    "print(\"Validation Set:\")\n",
    "print(type(Xqval), Xqval.shape)\n",
    "print(type(Xaval), Xaval.shape)\n",
    "print(type(Y_val), Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T40JWqkDTtaF"
   },
   "outputs": [],
   "source": [
    "# build vocab \n",
    "vocab = []\n",
    "\n",
    "for e in Xqtrain:\n",
    "  for word in e.split():\n",
    "    vocab.append(word)\n",
    "\n",
    "for e in Xatrain:\n",
    "  for word in e.split():\n",
    "    vocab.append(word)\n",
    "\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDEsnFPQus9O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122960\n"
     ]
    }
   ],
   "source": [
    "word2index={'pad': 0, 'unk': 1}\n",
    "\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "        \n",
    "index2word = {v:k for k, v in word2index.items()}\n",
    "\n",
    "target2index = {}\n",
    "\n",
    "for cl in set(Y_train):\n",
    "  if target2index.get(cl) is None:\n",
    "    target2index[cl] = len(target2index)\n",
    "\n",
    "    \n",
    "index2target = {v:k for k, v in target2index.items()}\n",
    "vocab_size = len(word2index)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./Model/word2index.pkl\", \"wb\") as handler:\n",
    "    pickle.dump(word2index, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6350,
     "status": "ok",
     "timestamp": 1563357523484,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "vdsWa7XAVW8Y",
    "outputId": "f5afecb3-ef1b-400a-e83f-aa3233b6c7de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72TzWV8Cu8dS"
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_index):\n",
    "    # idxs = list(map(lambda w: to_index[w] if to_index.get(w) is not None else to_index[\"<UNK>\"], seq))\n",
    "    idxs = []\n",
    "    for w in seq.split():\n",
    "      if w in word2index:\n",
    "        idxs.append(word2index[w])\n",
    "      else:\n",
    "        idxs.append(word2index[\"unk\"])\n",
    "    # return Variable(LongTensor(idxs))\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GhZzEdBiwZ6l"
   },
   "outputs": [],
   "source": [
    "Xq_p, Xa_p = [], []\n",
    "for xq, xa in zip(Xqtrain, Xatrain):\n",
    "  Xq_p.append(prepare_sequence(xq, word2index))\n",
    "  Xa_p.append(prepare_sequence(xa, word2index))\n",
    "Xq_train = pad_sequences(Xq_p, maxlen=16)\n",
    "Xa_train = pad_sequences(Xa_p, maxlen=128)\n",
    "\n",
    "Xq_p, Xa_p = [], []\n",
    "for xq, xa in zip(Xqval, Xaval):\n",
    "  Xq_p.append(prepare_sequence(xq, word2index))\n",
    "  Xa_p.append(prepare_sequence(xa, word2index))\n",
    "Xq_val = pad_sequences(Xq_p, maxlen=16)\n",
    "Xa_val = pad_sequences(Xa_p, maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13503,
     "status": "ok",
     "timestamp": 1563357534355,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "rEGRzKYwwZ9g",
    "outputId": "2c94f008-082e-45ff-f985-69df2709fa6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (350522, 16) [     0      0  28442  23627  91315  52878   7215  76085  68177  20505\n",
      "  94237 107978  38333  23323  36488  32533]\n",
      "<class 'numpy.ndarray'> (350522, 128) [     0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0  25473 111428 112915 118393\n",
      "  61856  42139  76674  41799  61856  31038 102127  18018]\n",
      "<class 'numpy.ndarray'> (42443, 16) [ 16847 112072  69376  52032 102018 107261  91742  68177 100130  42155\n",
      "  61856  33725  14971   7819  50403  58442]\n",
      "<class 'numpy.ndarray'> (42443, 128) [     0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0      0      0\n",
      "      0      0      0      0      0      0      0      0  43986  45742\n",
      "  11205  52878  58113  38333  32605  38333    411  54268  77215  98880\n",
      "  17015  68177  32799  26019 113081  68308 117849 113081  71916 109586\n",
      "  59273  50562  77766  91742  11205  41421  42495  11205]\n"
     ]
    }
   ],
   "source": [
    "print( type(Xq_train), Xq_train.shape, Xq_train[0] )\n",
    "print( type(Xa_train), Xa_train.shape, Xa_train[0] )\n",
    "\n",
    "print( type(Xq_val), Xq_val.shape, Xq_val[0] )\n",
    "print( type(Xa_val), Xa_val.shape, Xa_val[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1563357541109,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "W7kldGnfwaAa",
    "outputId": "5d9dafa2-81c8-4146-b9c2-547e2ff1740d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122960\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word2index)\n",
    "print(vocab_size)\n",
    "EMBEDDING_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nembedding_size = 100\\n\\npretrained = []\\nzero_embeddings = np.zeros((embedding_size,))\\ncount = 0\\n\\nfor key in word2index.keys():\\n    if key in fasttext_model.wv.vocab:\\n        count += 1\\n        pretrained.append( fasttext_model.wv[key] )\\n    else:\\n        pretrained.append( fasttext_model.wv[\"unk\"] )\\n\\nprint(count)\\npretrained_vectors = np.vstack(pretrained)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import gensim\n",
    "# from gensim.models import FastText\n",
    "# fasttext_model = FastText.load(\"./fasttext_embeddings/fasttext.model\")\n",
    "'''\n",
    "embedding_size = 100\n",
    "\n",
    "pretrained = []\n",
    "zero_embeddings = np.zeros((embedding_size,))\n",
    "count = 0\n",
    "\n",
    "for key in word2index.keys():\n",
    "    if key in fasttext_model.wv.vocab:\n",
    "        count += 1\n",
    "        pretrained.append( fasttext_model.wv[key] )\n",
    "    else:\n",
    "        pretrained.append( fasttext_model.wv[\"unk\"] )\n",
    "\n",
    "print(count)\n",
    "pretrained_vectors = np.vstack(pretrained)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fasttext_model.wv[\"unk\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1563357543851,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "IBn9iy4Btehv",
    "outputId": "c6ad2f8b-10aa-48ba-cf58-1535e3f74711"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110974\n"
     ]
    }
   ],
   "source": [
    "embeddings = starspace_embeddings\n",
    "embedding_size = 100\n",
    "\n",
    "pretrained = []\n",
    "zero_embeddings = np.zeros((embedding_size,))\n",
    "count = 0\n",
    "\n",
    "for key in word2index.keys():\n",
    "  # print(key)\n",
    "  if key in embeddings:\n",
    "    count += 1\n",
    "    pretrained.append( embeddings[key] )\n",
    "  else:\n",
    "    pretrained.append( np.random.randn(100) )\n",
    "\n",
    "print(count)\n",
    "pretrained_vectors = np.vstack(pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1563357545947,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "9oUxdqgqr1-i",
    "outputId": "1430939a-5afc-4a18-ee0a-82fbbc423651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (122960, 100)\n"
     ]
    }
   ],
   "source": [
    "print( type(pretrained_vectors) , pretrained_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1133,
     "status": "ok",
     "timestamp": 1563357550308,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "SfzI_dDlqOGr",
    "outputId": "1588b022-68e6-4dca-b0db-e154e38720f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.74498e-03, -1.39079e-02,  1.18770e-01, ..., -7.53179e-02,\n",
       "         3.80801e-02,  5.68262e-02],\n",
       "       [-4.98624e-02, -2.49910e-02, -1.71854e-02, ...,  1.73683e-02,\n",
       "         3.90429e-03, -2.50023e-02],\n",
       "       [ 3.93177e-02,  2.93438e-02,  1.96626e-03, ...,  3.86291e-03,\n",
       "         4.31270e-02,  6.19399e-02],\n",
       "       ...,\n",
       "       [ 5.61106e-02, -2.46822e-02,  5.14951e-02, ..., -2.67433e-02,\n",
       "        -5.53501e-02, -3.01738e-02],\n",
       "       [-5.45331e-02, -1.30692e-03,  4.95738e-02, ..., -1.53982e-02,\n",
       "         5.44395e-02,  2.93648e-02],\n",
       "       [-1.92501e-04, -1.00505e-04, -5.68038e-04, ...,  1.58721e-03,\n",
       "         1.06467e-03, -1.40518e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSJ_KT7tTws5"
   },
   "source": [
    "##  Building Modle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1563357553140,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "IxKxlW_XhOvT",
    "outputId": "2950d0da-f3ae-4538-fe84-ace3ab329857"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9bd2c97a70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, OrderedDict\n",
    "import nltk\n",
    "import re\n",
    "from copy import deepcopy\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "random.seed(1024)\n",
    "torch.manual_seed(777)  # reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OgcihPMNt9H0"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "gpus = [0]\n",
    "torch.cuda.set_device(gpus[0])\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if USE_CUDA else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if USE_CUDA else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2q-rsmNmuBT8"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "  \n",
    "  def __init__(self, vocab_size, embedding_dim, output_size, kernel_dim=100, kernel_sizes=(3, 4, 5), dropout=0.5):\n",
    "    \n",
    "    super(Encoder,self).__init__()\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "    self.convs = nn.ModuleList([nn.Conv2d(1, kernel_dim, (K, embedding_dim)) for K in kernel_sizes])\n",
    "    \n",
    "    # kernal_size = (K,D) \n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    # self.fc = nn.Linear(len(kernel_sizes) * kernel_dim, output_size)\n",
    "    self.linear1 = torch.nn.Linear(600, 1028, bias=True)\n",
    "    self.linear2 = torch.nn.Linear(1028, 128, bias=True)\n",
    "    self.linear3 = torch.nn.Linear(128, 4, bias=True)\n",
    "    self.linear4 = torch.nn.Linear(4, 4, bias=True)\n",
    "    \n",
    "    # torch.nn.init.xavier_uniform(self.linear1.weight)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "    self.dropout = torch.nn.Dropout(p=1 - keep_prob)\n",
    "    \n",
    "  def init_weights(self, pretrained_word_vectors, is_static=True):\n",
    "    torch.nn.init.xavier_uniform(self.linear1.weight)\n",
    "    torch.nn.init.xavier_uniform(self.linear2.weight)\n",
    "    torch.nn.init.xavier_uniform(self.linear3.weight)\n",
    "    torch.nn.init.xavier_uniform(self.linear4.weight)\n",
    "    self.embedding.weight = nn.Parameter(torch.from_numpy(pretrained_word_vectors).float())\n",
    "    # self.embedding.weight.requires_grad = False\n",
    "    if is_static:\n",
    "      self.embedding.weight.requires_grad = False\n",
    "    \n",
    "    \n",
    "  def encode(self, inputs):\n",
    "    inputs = self.embedding(inputs).unsqueeze(1) # (B,1,T,D)\n",
    "    inputs = [F.relu(conv(inputs)).squeeze(3) for conv in self.convs] \n",
    "    inputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in inputs]\n",
    "    concated = torch.cat(inputs, 1)\n",
    "    concated = self.dropout(concated)\n",
    "    return concated\n",
    "  \n",
    "  \n",
    "  def forward(self, xq, xa, is_training=False):\n",
    "    \n",
    "    encode_xq = self.encode(xq)\n",
    "    encode_xa = self.encode(xa)\n",
    "    \n",
    "    \n",
    "    x = torch.cat((encode_xq, encode_xa), 1)\n",
    "    # print(x.shape)\n",
    "    \n",
    "    x = self.linear1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.linear2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    \n",
    "    x = self.linear3(x)\n",
    "    # x = self.linear4(x)\n",
    "    # print(type(inputs), inputs.shape)\n",
    "    # print(inputs)\n",
    "    # print( self.embedding(inputs) )\n",
    "    # inputs = self.embedding(inputs).unsqueeze(1) # (B,1,T,D)\n",
    "    # inputs = [F.relu(conv(inputs)).squeeze(3) for conv in self.convs] \n",
    "    # inputs = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in inputs]\n",
    "    # concated = torch.cat(inputs, 1)\n",
    "    # print(\"concated\")\n",
    "    # print(concated, concated.shape)\n",
    "    # if is_training:\n",
    "    # concated = self.dropout(concated)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pPp5d2vdu2AR"
   },
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "KERNEL_SIZES = [3,4,5]\n",
    "KERNEL_DIM = 100\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 256\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1563357579246,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "6PFVPxuMu4_G",
    "outputId": "4370f82c-a21d-44aa-cbe0-533b123281ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhipeng/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/zhipeng/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/zhipeng/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "/home/zhipeng/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(len(word2index), 100, 3, KERNEL_DIM, KERNEL_SIZES)\n",
    "encoder.init_weights(pretrained_vectors) # initialize embedding matrix using pretrained vectors\n",
    "# net = Net(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSqCaXr-e2h1"
   },
   "outputs": [],
   "source": [
    "if USE_CUDA:\n",
    "    encoder = encoder.cuda()\n",
    "    # net = net.cuda()\n",
    "    \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# params = list(net.parameters()) + list(encoder.parameters())\n",
    "optimizer = optim.Adam(encoder.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2FourGUHvDtn"
   },
   "outputs": [],
   "source": [
    "train_question_inps = torch.from_numpy(Xq_train)\n",
    "train_question_inps = train_question_inps.type(torch.LongTensor).cuda()\n",
    "\n",
    "train_answer_inps = torch.from_numpy(Xa_train)\n",
    "train_answer_inps = train_answer_inps.type(torch.LongTensor).cuda()\n",
    "\n",
    "train_tgts = torch.from_numpy(Y_train)\n",
    "train_tgts = train_tgts.type(torch.LongTensor).cuda()\n",
    "\n",
    "\n",
    "val_question_inps = torch.from_numpy(Xq_val)[:5000]\n",
    "val_question_inps = val_question_inps.type(torch.LongTensor).cuda()\n",
    "\n",
    "val_answer_inps = torch.from_numpy(Xa_val)[:5000]\n",
    "val_answer_inps = val_answer_inps.type(torch.LongTensor).cuda()\n",
    "\n",
    "val_tgts = torch.from_numpy(Y_val)[:5000]\n",
    "val_tgts = val_tgts.type(torch.LongTensor).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 584,
     "status": "ok",
     "timestamp": 1563357591694,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "kXY9BdeY4r-K",
    "outputId": "022f2fed-cedd-4da1-a8b1-4a8d1d407442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([350522, 16])\n",
      "<class 'torch.Tensor'> torch.Size([350522, 128])\n",
      "<class 'torch.Tensor'> torch.Size([350522])\n",
      "<class 'torch.Tensor'> torch.Size([5000, 16])\n",
      "<class 'torch.Tensor'> torch.Size([5000, 128])\n",
      "<class 'torch.Tensor'> torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "print(type(train_question_inps), train_question_inps.shape)\n",
    "print(type(train_answer_inps), train_answer_inps.shape)\n",
    "print(type(train_tgts), train_tgts.shape)\n",
    "\n",
    "print(type(val_question_inps), val_question_inps.shape)\n",
    "print(type(val_answer_inps), val_answer_inps.shape)\n",
    "print(type(val_tgts), val_tgts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekl3QTdR5Vc_"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "train = data_utils.TensorDataset(train_question_inps, train_answer_inps, train_tgts)\n",
    "train_loader = data_utils.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1760040,
     "status": "ok",
     "timestamp": 1563365283396,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "us7yiHbu5p_X",
    "outputId": "460f913f-a035-46da-bf1d-e3e051684259",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: tensor(0.4766, device='cuda:0') tensor(1.0618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5000, device='cuda:0') tensor(1.0424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5156, device='cuda:0') tensor(1.0690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[Epoch:    1] cost = 1.05310094\n",
      "Validation Accuracy: tensor(0.4594, device='cuda:0') tensor(1.0145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5430, device='cuda:0') tensor(1.0963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5117, device='cuda:0') tensor(1.0855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5586, device='cuda:0') tensor(0.9999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[Epoch:    2] cost = 1.0525949\n",
      "Validation Accuracy: tensor(0.4628, device='cuda:0') tensor(1.0647, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5156, device='cuda:0') tensor(1.0552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.4961, device='cuda:0') tensor(1.0586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5117, device='cuda:0') tensor(1.0419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[Epoch:    3] cost = 1.05011117\n",
      "Validation Accuracy: tensor(0.4628, device='cuda:0') tensor(0.8916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5234, device='cuda:0') tensor(0.9796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.4805, device='cuda:0') tensor(1.1183, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5430, device='cuda:0') tensor(1.0039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[Epoch:    4] cost = 1.05029905\n",
      "Validation Accuracy: tensor(0.4572, device='cuda:0') tensor(1.1014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5547, device='cuda:0') tensor(0.9341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5273, device='cuda:0') tensor(1.0235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Training Accuracy: tensor(0.5586, device='cuda:0') tensor(1.0123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "[Epoch:    5] cost = 1.04909444\n",
      "Validation Accuracy: tensor(0.4572, device='cuda:0') tensor(0.9283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "encoder = encoder.train()  # explicitly set\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "  avg_cost = 0\n",
    "  total_batch = len(train) // BATCH_SIZE\n",
    "  # losses = []\n",
    "  for i, (batch_xqs, batch_xas, batch_ys) in enumerate(train_loader):\n",
    "    Xq = Variable(batch_xqs)\n",
    "    Xa = Variable(batch_xas)\n",
    "    Y = Variable(batch_ys)\n",
    "    \n",
    "    # print(type(Xq), Xq.shape)\n",
    "    # print(type(Xa), Xa.shape)\n",
    "    # print(type(Y), Y.shape)\n",
    "    \n",
    "    # net.zero_grad()\n",
    "    encoder.zero_grad()\n",
    "    preds = encoder(Xq, Xa)\n",
    "    \n",
    "    # print(\"preditions\", preds)\n",
    "    # print(\"gt\", Y)\n",
    "    \n",
    "    \n",
    "    cost = loss_function(preds, Y)\n",
    "    cost.backward()\n",
    "    \n",
    "    # for param in net.parameters():\n",
    "    #   param.grad.data.clamp_(-3, 3)\n",
    "    \n",
    "    # for param in encoder.parameters():\n",
    "    #   param.grad.data.clamp_(-3, 3)\n",
    "    \n",
    "    optimizer.step()\n",
    "    avg_cost += cost / total_batch\n",
    "    \n",
    "    if i % 500 == 0:\n",
    "      correct_prediction = (torch.max(preds.data, 1)[1] == Y.data)\n",
    "      accuracy = correct_prediction.float().mean()\n",
    "      print('Training Accuracy:', accuracy, cost)\n",
    "    \n",
    "    # break\n",
    "  \n",
    "  print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost.data))\n",
    "  \n",
    "  Xq_val = Variable(val_question_inps) \n",
    "  Xa_val = Variable(val_answer_inps)\n",
    "  Y_val = Variable(val_tgts)\n",
    "  val_preds = encoder(Xq_val, Xa_val)\n",
    "  correct_prediction = (torch.max(val_preds.data, 1)[1] == Y_val.data)\n",
    "  accuracy = correct_prediction.float().mean()\n",
    "  print('Validation Accuracy:', accuracy, cost)\n",
    "  \n",
    "  # break\n",
    "  # del Xq_val, Xa_val, Y_val, val_preds\n",
    "  \n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUJNA1KUDQtH"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jEFIpGLBDSRR"
   },
   "outputs": [],
   "source": [
    "def hits_count(candidate_ranks, k):\n",
    "  '''\n",
    "    candidate_ranks:\n",
    "    list of candidates' ranks; one rank per question;\n",
    "    length is a number of questions\n",
    "    rank is a number from q to len(candidates of the question)\n",
    "    e.g. [2, 3] means that first candidate has the rank 2,\n",
    "                           second candidate has the rank 3\n",
    "    k: number of top-ranked elements (k in hits@k metric)\n",
    "    result: return Hits@k value for current ranking \n",
    "  '''\n",
    "  count = 0\n",
    "  for rank in candidate_ranks:\n",
    "    if rank <= k:\n",
    "      count += 1\n",
    "  return count/(len(candidate_ranks)+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vG2NqkIgDW9T"
   },
   "outputs": [],
   "source": [
    "def dcg_score(candidate_ranks, k):\n",
    "  '''\n",
    "    candidate_ranks:\n",
    "    list of candidates' ranks; one rank per question;\n",
    "    length is a number of questions\n",
    "    rank is a number from q to len(candidates of the question)\n",
    "    e.g. [2, 3] means that first candidate has the rank 2,\n",
    "                           second candidate has the rank 3\n",
    "    k: number of top-ranked elements (k in hits@k metric)\n",
    "    \n",
    "    result: return DCG@k value for current ranking\n",
    "  '''\n",
    "  score = 0\n",
    "  for rank in candidate_ranks:\n",
    "    if rank <= k:\n",
    "      score += 1/np.log2(1+rank)\n",
    "  return score/(len(candidate_ranks)+1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_qa_pairs = []\n",
    "with open('./evaluation_data', 'r') as evaluation_data:\n",
    "  for line in evaluation_data:\n",
    "    qa = line.strip().split('\\t')\n",
    "    # print(len(qa))\n",
    "    # print(qa)\n",
    "    question = qa[0]\n",
    "    prediction = qa[1] \n",
    "    question = question + ' '.join(set(text_prepare(prediction).split()))\n",
    "    # print(question)\n",
    "    candidate_answers = qa[2:7]\n",
    "    \n",
    "    # print(prediction)\n",
    "    # print(candidate_answers)\n",
    "    # break\n",
    "    evaluation_qa_pairs.append( (question, candidate_answers) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1563365376946,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "GFH7TEPyD8h5",
    "outputId": "5c480fd3-1a60-4f8d-facb-d6133cb944f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (embedding): Embedding(122960, 100)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (linear1): Linear(in_features=600, out_features=1028, bias=True)\n",
       "  (linear2): Linear(in_features=1028, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=4, bias=True)\n",
       "  (linear4): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model \n",
    "encoder.eval()    # set the model to evaluation mode (dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nW9MD4zFHq59"
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidate_answers, model):\n",
    "  '''\n",
    "    question: a string\n",
    "    candidate_answers : a list of strings\n",
    "    \n",
    "    result: a list of pairs (initial position in the list, question)\n",
    "  '''\n",
    "  candidate_scores = []\n",
    "  for answer in candidate_answers:\n",
    "    # question_vec = query_to_vec(question, starspace_embeddings, dim=100)\n",
    "    # answer_vec = query_to_vec(answer, starspace_embeddings, dim=100)\n",
    "    \n",
    "    Xq_p, Xa_p = [], []\n",
    "    Xq_p.append(prepare_sequence(question, word2index))\n",
    "    Xa_p.append(prepare_sequence(answer, word2index))\n",
    "    \n",
    "    # print(Xq_p)\n",
    "    # print(Xa_p)\n",
    "    \n",
    "    Xq_val = torch.from_numpy( pad_sequences(Xq_p, maxlen=16)  )\n",
    "    Xq_val = Xq_val.type(torch.LongTensor).cuda()\n",
    "    \n",
    "    Xa_val = torch.from_numpy( pad_sequences(Xa_p, maxlen=128) )\n",
    "    Xa_val = Xa_val.type(torch.LongTensor).cuda()\n",
    "    \n",
    "    \n",
    "    Xq_val = Variable(Xq_val)\n",
    "    Xa_val = Variable(Xa_val)\n",
    "    \n",
    "    preds = encoder(Xq_val, Xa_val)\n",
    "    preds = F.softmax( preds ) \n",
    "    \n",
    "    # print( type(preds), preds.shape, preds)\n",
    "    \n",
    "    np_prediction = preds.detach().cpu().numpy()\n",
    "    # print(np_prediction, np_prediction[0][-1])\n",
    "    ########################################\n",
    "    ######## Check here !!! Important ######\n",
    "    ########################################\n",
    "    score = (-2.*np_prediction[0][0]) + (-1.*np_prediction[0][1]) + (1.*np_prediction[0][2]) + (2.*np_prediction[0][3])\n",
    "    candidate_scores.append( score )\n",
    "    # candidate_scores.append( np_prediction[0][-1] )\n",
    " \n",
    "    \n",
    "  tl = [(i, candidate_answers[i], candidate_scores[i]) for i in range(len(candidate_answers))]\n",
    "  # print(tl)\n",
    "  stl = sorted(tl, key=lambda x:x[2], reverse=True)\n",
    "  result = [(t[0],t[1]) for t in stl]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70475,
     "status": "ok",
     "timestamp": 1563365449207,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "om08Hd4REXHv",
    "outputId": "7e8102b1-9a69-4904-b11e-814f6df19f36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhipeng/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# load model \n",
    "encoder.eval()    # set the model to evaluation mode (dropout=False)\n",
    "# Test model and check accuracy\n",
    "model_ranking = []\n",
    "model = encoder\n",
    "\n",
    "for qa_pair in evaluation_qa_pairs:\n",
    "\n",
    "  question = qa_pair[0]\n",
    "  candidate_answers = qa_pair[1]\n",
    "  \n",
    "  ranks = rank_candidates(question, candidate_answers, model)\n",
    "  # print(ranks)\n",
    "  model_ranking.append( [r[0] for r in ranks].index(0) + 1 )\n",
    "  # break\n",
    "  # print(ranks)\n",
    "  # model_ranking.append( [r[0] for r in ranks].index(0) + 1 )\n",
    "  # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 68503,
     "status": "ok",
     "timestamp": 1563365449209,
     "user": {
      "displayName": "Zhipeng Gao",
      "photoUrl": "",
      "userId": "13688102955547804069"
     },
     "user_tz": -600
    },
    "id": "KLD6cTKfG0ST",
    "outputId": "2e964359-48c6-4554-980e-a512eb7e0d9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.400 | Hits@   1: 0.400\n",
      "DCG@   2: 0.559 | Hits@   2: 0.652\n",
      "DCG@   3: 0.641 | Hits@   3: 0.817\n",
      "DCG@   4: 0.690 | Hits@   4: 0.930\n",
      "DCG@   5: 0.717 | Hits@   5: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in [1, 2, 3, 4, 5]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(model_ranking, k), \n",
    "                                               k, hits_count(model_ranking, k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder, './Model/expansion-40.6.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-for-Text-Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
